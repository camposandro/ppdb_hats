{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b474b22",
   "metadata": {},
   "source": [
    "## Import PPDB base catalog\n",
    "\n",
    "This notebook imports the base PPDB catalog (2025/26 fall and winter data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d453639c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tempfile\n",
    "\n",
    "from dask.distributed import Client\n",
    "from datetime import date\n",
    "from hats_import import pipeline_with_client\n",
    "from hats_import.catalog import ImportArguments\n",
    "from hats_import.collection.arguments import CollectionArguments\n",
    "from ppdb_hats.daily.ingest import import_catalog\n",
    "from ppdb_hats.daily.nest import load_sources_with_margin, nest_sources\n",
    "from nested_pandas.utils import count_nested\n",
    "from pathlib import Path\n",
    "from ppdb_hats.daily.paths import get_paths, append_input_paths\n",
    "from ppdb_hats.daily.postprocess import postprocess_catalog\n",
    "from ppdb_hats.config import get_default_config\n",
    "\n",
    "# Pipeline configuration\n",
    "config = get_default_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd674a39",
   "metadata": {},
   "source": [
    "Set up the input/output dirs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba84afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSST PPDB repository\n",
    "PPDB_DIR = Path(\"/sdf/scratch/rubin/ppdb/data/ppdb_lsstcam\")\n",
    "\n",
    "# Base HATS directory\n",
    "output_dir = Path(\"/sdf/data/rubin/shared/lsdb_commissioning/ppdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f27ce28",
   "metadata": {},
   "source": [
    "Set up the Dask client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c9c0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary directory\n",
    "tmp_dir = Path(tempfile.TemporaryDirectory().name)\n",
    "print(f\"Intermediate directory: {tmp_dir}\")\n",
    "\n",
    "# Dask client\n",
    "client = Client(n_workers=16, memory_limit=\"8GB\", threads_per_worker=1, local_directory=tmp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b7f2eb",
   "metadata": {},
   "source": [
    "### Get input files for each dataset type\n",
    "\n",
    "We will grab all files until Jan 20, inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4530043",
   "metadata": {},
   "outputs": [],
   "source": [
    "until_date = date(2026, 1, 20)\n",
    "object_files = get_paths(\"dia_object\", PPDB_DIR, until_date=until_date)\n",
    "source_files = get_paths(\"dia_source\", PPDB_DIR, until_date=until_date)\n",
    "fsource_files = get_paths(\"dia_forced_source\", PPDB_DIR, until_date=until_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f893ea",
   "metadata": {},
   "source": [
    "### Import base catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7a512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_catalog(client, tmp_dir, \"dia_object\", object_files, config.import_config)\n",
    "import_catalog(client, tmp_dir, \"dia_source\", source_files, config.import_config)\n",
    "import_catalog(client, tmp_dir, \"dia_forced_source\", fsource_files, config.import_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3385a154",
   "metadata": {},
   "source": [
    "### Post-processing\n",
    "\n",
    "About 8% of objects have duplicates (same `diaObjectId`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8a9114",
   "metadata": {},
   "outputs": [],
   "source": [
    "dia_object = lsdb.open_catalog(tmp_dir / \"dia_object\")\n",
    "_, counts = np.unique(dia_object[\"diaObjectId\"], return_counts=True)\n",
    "n_dup_ids = np.sum(counts > 1)\n",
    "n_dup_ids / len(dia_object) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94be3b35",
   "metadata": {},
   "source": [
    "We will keep the oned of latest `validityStartMjdTai`, and add mag/magerr columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7404e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_time_cols = config.postprocess_config.position_time_cols\n",
    "\n",
    "postprocess_catalog(\n",
    "    client,\n",
    "    tmp_dir,\n",
    "    \"dia_object\",\n",
    "    position_time_cols=position_time_cols,\n",
    "    validity_col=\"validityStartMjdTai\",\n",
    "    flux_colnames=[f\"{band}_scienceFluxMean\" for band in \"ugrizy\"],\n",
    ")\n",
    "postprocess_catalog(\n",
    "    client,\n",
    "    tmp_dir,\n",
    "    \"dia_source\",\n",
    "    position_time_cols=position_time_cols,\n",
    "    flux_colnames=[\"scienceFlux\"],\n",
    ")\n",
    "postprocess_catalog(\n",
    "    client,\n",
    "    tmp_dir,\n",
    "    \"dia_forced_source\",\n",
    "    position_time_cols=position_time_cols,\n",
    "    flux_colnames=[\"scienceFlux\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc408f9",
   "metadata": {},
   "source": [
    "### Nest sources in objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf8e57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dia_object = lsdb.read_hats(tmp_dir / \"dia_object\")\n",
    "margin_threshold = config.margin_threshold\n",
    "dia_source = load_sources_with_margin(client, tmp_dir, \"dia_source\", margin_threshold)\n",
    "dia_forced_source = load_sources_with_margin(client, tmp_dir, \"dia_forced_source\", margin_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc1aadb",
   "metadata": {},
   "source": [
    "There are ~6% of sources with no `diaObjectId`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972cddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sources_no_objid = np.sum(dia_source[\"diaObjectId\"].isna().compute())\n",
    "n_sources_no_objid / len(dia_source) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f3eb2a",
   "metadata": {},
   "source": [
    "We'll need to filter them out otherwise we cannot nest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83de027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dia_source = dia_source[~dia_source[\"diaObjectId\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cac5d2",
   "metadata": {},
   "source": [
    "That does not seem to be an issue for `diaForcedSource`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3939e846",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(dia_forced_source[\"diaObjectId\"].isna().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7304fe58",
   "metadata": {},
   "source": [
    "Nest sources and forced sources and write to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef546e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dia_object_lc = nest_sources(dia_object, valid_dia_source, dia_forced_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf32fac",
   "metadata": {},
   "source": [
    "Save the results to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423847d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dia_object_lc.write_catalog(tmp_dir, catalog_name=\"dia_object_lc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68cbb6e",
   "metadata": {},
   "source": [
    "Let's reimport with leaf pixel directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7dca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "dia_collection_dir = config.paths.dia_object_collection_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a29f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ImportArguments.reimport_from_hats(\n",
    "    tmp_dir / \"dia_object_lc\",\n",
    "    output_dir=dia_collection_dir,\n",
    "    byte_pixel_threshold=1 << 30,\n",
    "    npix_suffix=\"/\",\n",
    "    addl_hats_properties={\"hats_npix_suffix\": \"/\"},\n",
    "    simple_progress_bar=True,\n",
    ")\n",
    "pipeline_with_client(args, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc82cf8",
   "metadata": {},
   "source": [
    "### Finish collection\n",
    "\n",
    "Generate margin and index catalogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3853fb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = (\n",
    "    CollectionArguments(\n",
    "        output_artifact_name=\"dia_object_collection\",\n",
    "        new_catalog_name=\"dia_object_lc\",\n",
    "        output_path=output_dir,\n",
    "        simple_progress_bar=True,\n",
    "    )\n",
    "    .catalog(\n",
    "        catalog_path=dia_collection_dir / \"dia_object_lc\",\n",
    "    )\n",
    "    .add_margin(margin_threshold=5.0, is_default=True)\n",
    "    .add_index(indexing_column=\"diaObjectId\")\n",
    ")\n",
    "pipeline_with_client(args, client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97166169",
   "metadata": {},
   "source": [
    "Let's also store which files we ingested in this run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a34fb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "append_input_paths(\"dia_object\", object_files, dia_collection_dir)\n",
    "append_input_paths(\"dia_source\", source_files, dia_collection_dir)\n",
    "append_input_paths(\"dia_forced_source\", fsource_files, dia_collection_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec7f30d",
   "metadata": {},
   "source": [
    "### Some validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f32a9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = lsdb.open_catalog(output_dir / \"dia_object_collection\").compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfc0a96",
   "metadata": {},
   "source": [
    "#### Checking objects\n",
    "\n",
    "We have the same set of objects in the collection as in the original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d94aeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_objs = pd.read_parquet(object_files, dtype_backend=\"pyarrow\")\n",
    "input_obj_ids = np.unique(input_objs[\"diaObjectId\"])\n",
    "assert set(df[\"diaObjectId\"]) == set(input_obj_ids)\n",
    "assert len(input_obj_ids) == len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39235b76",
   "metadata": {},
   "source": [
    "#### Checking sources\n",
    "\n",
    "All objects have sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db4d360",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[~df[\"diaSource\"].isna()]) / len(df) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3135c35",
   "metadata": {},
   "source": [
    "There are as many sources in the collection as in the base catalog (minus those with no diaObjectId):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906c3407",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sources = pd.read_parquet(source_files, dtype_backend=\"pyarrow\")\n",
    "expected_sources = input_sources[~input_sources[\"diaObjectId\"].isna()]\n",
    "assert len(expected_sources) == len(df[\"diaSource\"].explode())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891fcf39",
   "metadata": {},
   "source": [
    "Though there are ~7% of objects for which \"nDiaSource\" doesn't match the number of \"diaSource\" we got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8451e4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = count_nested(df, \"diaSource\", join=True)\n",
    "unmatched = count_df[count_df[\"nDiaSources\"] != count_df[\"n_diaSource\"]]\n",
    "len(unmatched) / len(count_df) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978d20d2",
   "metadata": {},
   "source": [
    "#### Checking forced sources\n",
    "\n",
    "Only ~5% of objects have forced sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3308d216",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[~df[\"diaForcedSource\"].isna()]) / len(df) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba8381c",
   "metadata": {},
   "source": [
    "This seems to make sense according to the input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7772dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "forced_sources = pd.read_parquet(fsource_files, dtype_backend=\"pyarrow\")\n",
    "expected_f_sources = forced_sources[~forced_sources[\"diaObjectId\"].isna()]\n",
    "assert len(expected_f_sources) == len(df[\"diaForcedSource\"].explode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90a57b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
